# Map端Shuffle

1. MapTask调用`map()`方法处理数据，默认情况下是读取一行处理一行。`map()`方法在处理完数据之后，会将这个数据写到MapTask自带的缓冲区中

   > 每一个MapTask都会自带一个缓冲区

2. 数据在缓冲区中进行分区、排序，如果指定了Combiner，那么还会进行combine合并

   > 数据在缓冲区中进行排序的时候，将完全杂乱的数据排成有序的数据，这个过程采用的是==快速排序==

3. 缓冲区本质上是一个环形的字节数组，默认大小是100MB，维系在内存中

4. 当缓冲区使用达到阈值的时候，会将缓冲区的数据进行溢写(spill)，将缓冲区中的数据溢写到磁盘上，产生一个溢写文件

   > 溢写阈值默认是0.8，即表示当缓冲区的容量使用达到80%的时候进行溢写

5. 当缓冲区溢写之后，MapTask产生的新数据依然是放到缓冲区中，达到条件再次溢写，每一次溢写都会产生一个新的溢写文件

6. 单个溢写文件中的数据应该是分好区且排好序的，多个溢写文件之间是整体无序的，但局部是有序的

7. 在MapTask处理完所有数据之后，会将所有的溢出文件进行==合并==(merge)，合并成一个文件==(final out)==；

   > - 如果MapTask处理完之后，一部分结果在溢写文件中，一部分结果在缓冲区中，那么就将溢写文件和缓冲区中的数据都merge到final out
   > - 如果没有产生溢写过程，那么MapTask在处理完成之后会将数据直接写到final out中。
   >
   > 也就意味着MapTask在处理完数据之后一定会产生一个final out文件

8. 在merge过程中，数据会再次进行分区排序，所以final out文件中数据都是分好区且排好序的。如果制定了Combiner，会在溢写文件>=3个时，在merge过程会进行combine操作

   > merge过程中的排序是将局部有序的数据整理为整体有序的数据，这个过程采用==归并排序==



**注意问题：**

> - 溢写过程不一定会产生
> - 原始数据的大小并不能决定是否溢写，得看MapTask处理之后产生的数据量，而不是处理之前的数据量
> - 溢写过程本质上是数据从内存写到磁盘的过程，这个过程中要考虑序列化因素，所以溢写文件的大小不一定等于【缓冲区大小*溢写阈值】
> - 将缓冲区设置为环形的目的是为了重复利用这个缓冲区，而且不用频繁的寻址
> - 设置溢写阈值的目的是为了尽量减少甚至避免MapTask在写出结果过程中产生阻塞



![](https://gitee.com/sxhDrk/images/raw/master/imgs/Map端Shuffle过程.png)



> Map阶段的处理流程

![](https://gitee.com/sxhDrk/images/raw/master/imgs/Map阶段流程.png)



# Reduce端Shuffle

1. ReduceTask启动阈值默认是`0.05`，即当有5%的MapTask执行结束之后，就会启动ReduceTask来抓取数据

2. ReduceTask启动fetch线程通过http请求去MapTask抓取数据，在抓取数据的时候只抓取当前ReduceTask处理的分区数据

   > 默认每一个ReduceTask可以启动5个fetch线程

3. ReduceTask通过fetch线程抓取到数据之后，每一段数据都会临时存储在本地的一个小文件中，在抓取完成之后，会对这个小文件进行==merge==(合并)，在merge过程中，数据会再次进行排序

   > 这一次排序依然是将数据从局部有序整理成 - 整体有序，采用==归并排序==
   >
   > 在Reduce的merge过程中，merge因子默认为10，即每10个小文件合并成一个文件

4. merge完成之后，会将相同的键对应的值放到一组中，这个过程称之为：==分组==(group)；分组完成之后，每一个键调用一次`Reduce()`方法计算结果

   > 分组之后，这一组值会产生一个迭代器，对应了reduce()方法中的values，这个迭代器实际上是一个伪迭代器
   >
   > 在分组的时候，实际上并不是真的产生了一个迭代器，而是去读取文件中数据，每次从这个文件中读取2行数据，比较2行数据的键是否一致
   >
   > - 如果一致，则将第一行读取到的数据放到reduce中处理，同时继续读取
   > - 如果不一致，就会标记第二行重新调用reduce()方法，同时标记上一行迭代结束
   >
   > 这里的迭代器本质上不是产生一个容器，而是去读取文件
   >
   > ![](https://gitee.com/sxhDrk/images/raw/master/imgs/MapReduce中的伪迭代器.png)



> Reduce阶段的处理流程

![](https://gitee.com/sxhDrk/images/raw/master/imgs/Reduce阶段流程.png)



# Shuffle整体流程

> 参考图片1：👇👇👇

![](https://gitee.com/sxhDrk/images/raw/master/imgs/Shuffle整理流程.png)

> 参考图片2：👇👇👇

![](https://gitee.com/sxhDrk/images/raw/master/imgs/Shuffle整体流程.png)



# Shuffle优化

1. ⭐**增大缓冲区**。在实际开发过程中，会将缓冲区大小设置为250MB~400MB
2. **增大溢写阈值**。例如：可以将阈值增大到0.9，但是这种方案可能会增加线程阻塞的风险
3. ⭐**尽量增加Combiner过程**
4. ⭐**如果网络资源比较紧张，可以适当对final out进行压缩**。但是同样ReduceTask通过fetch线程抓取到数据之后需要进行解压。所以这个方法是对网络资源和解压时间的取舍
5. ⭐**适当增加fetch的线程数量**。需要考虑服务器的线程承载量
6. **增大merge因子**。这种方案增加底层运算的复杂度，不建议使用
7. **适当的调小ReduceTask的启动阈值**。实际过程中不建议调节