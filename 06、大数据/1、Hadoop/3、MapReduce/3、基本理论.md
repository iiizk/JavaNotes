[TOC]

# 数据本地化策略

1. 当JobTracker访问资源的时候需要向NameNode请求数据
2. JobTracker获取到数据的描述信息，根据描述信息对数据进行了切片（InputSplit），然后将切片发给不同MapTask来执行
3. MapTask在TaskTracker上执行，在执行的时候需要获取实际的数据
4. TaskTracker需要去访问DataNode，为了节省带宽资源，所以往往将DataNode和TaskTracker放在同一个节点上 --- ==数据本地化策略==
5. 为了减少网络资源的消耗，往往还会将切片的大小和实际的Block的大小设置的相同

![](https://gitee.com/sxhDrk/images/raw/master/imgs/切片阈值.png)

> **JobTracker**：对外接收任务，拆分任务；对内管理TaskTracker
>
> **TaskTracker**：执行任务
>
> **Split**：切片，对数据的逻辑切片，每一个线程要处理的数据量，每一个Split会分配一个MapTask
>
> **Block**：切块，数据真正的物理切片，数据的存储大小



## 切片过程

1. 如果文件为空（即文件大小是0B），将整个文件作为一个切片来处理

2. 在MapReduce中，文件分为==可切分==和==不可切分==。

   > 注意：这个切分和不可切分指的是逻辑切分。例如绝大部分的压缩文件都是不可切的

3. 如果文件不可切（不能逻辑切分），那么将整个文件作为一个切片来处理

4. 默认情况下，Split大小和Block大小是一致的

5. 如果需要调整Split大小

   - 调大SplitSize，需要调大minSize
   - 调小SplitSize，需要调小maxSize

   ==底层代码==

   ```java
   protected long computeSplitSize(long blockSize,long minSize,long maxSize){
       return Math.max(minSize,Math.max(maxSize,blockSize));
   }
   ```

   ==Driver类代码==

   ```java
   //设置minSize
   FileInputFormat.setMinInputSplitSize(xxx);
   //设置maxSize
   FileInputFormat.setMaxInputSplitSize(xxx);
   ```

6. 在计算分片的时候，需要注意这个切片的阈值。

   > 切片阈值默认1.1，即 `剩余字节个数/splitSize > 1.1`的时候才会计算分片
   >
   > 如果 `剩余字节个数/splitSize <= 1.1`，那么剩余的字节个数整体作为1个切片处理

   ![](https://gitee.com/sxhDrk/images/raw/master/imgs/Map阶段流程.png)



# MapReduce执行流程

## Map阶段流程

![](https://gitee.com/sxhDrk/images/raw/master/imgs/Shuffle整体流程.png)



## Reduce阶段流程

![](https://gitee.com/sxhDrk/images/raw/master/imgs/本地化策略.png)



## 整体流程

> 参考图片1：

![](https://gitee.com/sxhDrk/images/raw/master/imgs/MapReduce流程.png)

 

> 参考图片2：

![](https://gitee.com/sxhDrk/images/raw/master/imgs/MapReduce整体流程.png)



> 参考图片3：

![](https://gitee.com/sxhDrk/images/raw/master/imgs/Reduce阶段流程.png)



# Job执行流程

## 提交流程

1. 检查输入和输出路径
   - 检查输入路径是否存在，如果不存在抛出FileNotFountException
   - 检查输出路径是否存在
     - 如果存在，抛出FileAlreadyExitsException
     - 如果不存在，就会常见这个路径
2. 计算切片数量，产生切片
3. 如果有需要，可以为分布式缓存设置存根账户信息
4. 将这个任务的jar包和配置信息提交到HDFS上存储，完成后会删除
5. 将job提交给JobTracker，并且选择是否监控这个job的执行状态

## 执行流程

1. JobTracker在收到Job任务之后，会将这个Job任务拆分成MapTask和ReduceTask

   - MapTask的数量由切片数量来决定
   - ReduceTask的数量由分区数量来决定

   拆分完成后，JobTracker等待TaskTracker的心跳

2. JobTracker在收到TaskTracker的心跳之后，会分配任务。

   > 注意：再分配任务的时候MapTask要考虑数据本地化，ReduceTask则要分配到相对空闲的节点上。在这个过程中，每一个TaskTracker不一定只领取到一个任务，可能会领取多个任务

3. TaskTracker通过心跳领取到任务之后，连接对应的节点将jar包下载过来，解析jar包获取执行逻辑，这一步体现了：==逻辑移动，数据固定==的思想

4. TaskTracker解析完jar包之后，在本节点（服务器）上开启一个JVM子进程执行MapTask或者ReduceTask。

   > 默认情况下，每执行一个MapTask或者ReduceTask就会开启一次JVM子进程，执行完成之后就会关闭这个JVM子进程。也就意味着，如果一个TaskTracker领取到多个任务，那么就会开启和关闭多次JVM子进程