[TOC]



# InputFormat - 输入格式

1. InputFormat是MapReduce中提供的一个输入格式的顶级父类，提供了2个方法：
   - `getSplits`：规定切片的过程
   - `createRecordReader`：针对指定的切片来提供输入流来读取数据的
   
2. InputFormat发生在Map之前。在MapTask之前，先对文件切片，然后提供输入流读取数据，将读取的数据发送给MapTask，也就意味着InputFormat读出来的数据是什么格式，Mapper接收到数据就是什么格式

3. 在默认情况下，输入格式类用的是：`TextInputFormat`，默认是按行读取，然后将读取的数据发送给Map。在TextInputFormat中，为了保证数据的完整性，每一个MapTask都是从当前切片的第二行开始，处理到下一个切片的第一行

   

   ![](https://gitee.com/sxhDrk/images/raw/master/imgs/InputFormat.png)

   

## 自定义输入格式

> 写一个类继承InputFormat，考虑到切片过程相对比较繁琐，可以考虑继承`FileInputFormat`，这个类中实现了`getSplit()`方法，只需要覆盖`createRecordReader()`即可



### 源文件

> 统计该文件的每个人的总分。
>
> 因为不像正常的一人一行数据，这个文件是一个人，三行数据，需要自定义输入格式，每次读三行

```
tom
math 90
english 98
jary
math 78
english 87
rose
math 87
english 90
bob
math 67
english 87
alex
math 59
english 80
helen
math 79
english 60
```



### 自定义的InputFormat类

```java
// 泛型表示的输出类型 - 泛型定义的是什么类型，那么Mapper接收的就是类型
public class AuthInputFormat extends FileInputFormat<Text, Text> {
    @Override
    public RecordReader<Text, Text> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {
        return new AuthReader();
    }
}

class AuthReader extends RecordReader<Text, Text> {

    private LineReader reader;
    private Text key;
    private Text value;
    private static final byte[] blank = new Text(" ").getBytes();

    // 初始化的方法，在这个方法中一般获取一个真正的用于读取数据的流
    @Override
    public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {

        // 获取地址
        FileSplit fsplit = (FileSplit) split;
        Path path = fsplit.getPath();
        URI uri = URI.create(path.toString());
        // 连接HDFS
        FileSystem fs = FileSystem.get(uri, context.getConfiguration());
        // 获取输入流用于读取数据
        InputStream in = fs.open(path);
        // 获取的这个输入流是一个字节流
        // 目的是为了读取3行，每3行组成1条数据 - 字节流在读取的时候还得自己判断什么时候才读完三行
        // 考虑将字节流包装成字符流，并且这个字符流最好能够按行读取
        reader = new LineReader(in);

    }

    // 判断是否有下一个键值对来提供给map方法处理，如果有返回true
    // 可以试图读取数据，如果读取到了数据，那么说明还有数据提供给map处理，返回true
    // 如果没有读取到数据，那么说明所有的数据已经读取完了，那么map方法也没有数据处理，返回false
    @Override
    public boolean nextKeyValue() throws IOException, InterruptedException {

        // 初始化变量
        key = new Text();
        value = new Text();
        Text tmp = new Text();
        // 试图读取
        // 读取第一行
        // 如果没有读取到数据，返回0
        if (reader.readLine(tmp) == 0) return false;
        key.set(tmp.toString());
        // 读取第二行
        if (reader.readLine(tmp) == 0) return false;
        value.set(tmp.toString());
        
        // 需要在值之间拼接空格
        value.append(blank, 0, blank.length);
        
        // 读取第三行
        if (reader.readLine(tmp) == 0) return false;
        byte[] data = tmp.getBytes();
        value.append(data, 0, data.length);
        // 读取完成之后的结构
        // key = tom
        // value = math 90 english 98

        return true;
    }

    // 获取键
    @Override
    public Text getCurrentKey() throws IOException, InterruptedException {
        return key;
    }

    // 获取值
    @Override
    public Text getCurrentValue() throws IOException, InterruptedException {
        return value;
    }

    // 获取当前MapTask的执行进度 - 实际上就是获取数据读取的进度
    // 是否覆盖这个方法对整个结果没有影响
    @Override
    public float getProgress() throws IOException, InterruptedException {
        return 0;
    }

    // 回收
    @Override
    public void close() throws IOException {
        if (reader != null)
            reader.close();
        key = null;
        value = null;
    }

}
```



### Score类

```java
public class Score implements Writable {

    private int math;
    private int english;

    public int getMath() {return math;}

    public void setMath(int math) {this.math = math;}

    public int getEnglish() {return english;}

    public void setEnglish(int english) {this.english = english;}

    @Override
    public void write(DataOutput out) throws IOException {
        out.writeInt(math);
        out.writeInt(english);
    }

    @Override
    public void readFields(DataInput in) throws IOException {
        this.math = in.readInt();
        this.english = in.readInt();
    }
}
```



### Mapper类

```java
public class AuthMapper extends Mapper<Text, Text, Text, Score> {
    @Override
    protected void map(Text key, Text value, Context context) throws IOException, InterruptedException {
        // key = tom
        // value = math 90 english 98
        String[] arr = value.toString().split(" ");
        Score s = new Score();
        s.setMath(Integer.parseInt(arr[1]));
        s.setEnglish(Integer.parseInt(arr[3]));
        context.write(key, s);
    }
}
```



### Reducer类

```java
public class AuthReducer extends Reducer<Text, Score, Text, IntWritable> {
    @Override
    protected void reduce(Text key, Iterable<Score> values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        Score s = values.iterator().next();
        sum += s.getMath() + s.getEnglish();
        context.write(key, new IntWritable(sum));
    }
}
```



### Driver类

```java
public class AuthDriver {
    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf);

        job.setJarByClass(AuthDriver.class);
        job.setMapperClass(AuthMapper.class);
        job.setReducerClass(AuthReducer.class);

        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(Score.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        // 指定输入格式类
        job.setInputFormatClass(AuthInputFormat.class);

        FileInputFormat.addInputPath(job,
                         new Path("hdfs://hadoop01:9000/txt/score3.txt"));
        FileOutputFormat.setOutputPath(job,
                         new Path("hdfs://hadoop01:9000/result/authinput"));

        job.waitForCompletion(true);
    }
}
```



### 结果

```
tom		188
jary	165
rose 	177
bob		154
alex	139
helen	139
```



## 多源输入

> 一次性的指定多个输入路径，并且允许为不同的输入路径来指定不同的Input Format以及Mapper类
>
> `MultipleInputs.addInputPath(Job,Path,输入格式类,Mapper)`

### Mapper类1

```java
// 处理score.txt
public class ScoreMapper1 extends Mapper<LongWritable, Text, Text, IntWritable> {
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        // Alex 64 63 68
        String[] arr = value.toString().split(" ");
        Text name = new Text(arr[0]);
        for (int i = 1; i < arr.length; i++) {
            context.write(name, new IntWritable(Integer.parseInt(arr[i])));
        }

    }
}
```



### Mapper类2

```java
// 处理score3.txt
public class ScoreMapper2 extends Mapper<Text, Text, Text, IntWritable> {
    @Override
    protected void map(Text key, Text value, Context context) throws IOException, InterruptedException {
        // key = tom
        // value = math 90 english 98
        String[] arr = value.toString().split(" ");
        context.write(key, new IntWritable(Integer.parseInt(arr[1])));
        context.write(key, new IntWritable(Integer.parseInt(arr[3])));
    }
}
```



### Reducer类

```java
public class ScoreReducer extends Reducer<Text, IntWritable, Text, Text> {
    @Override
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        double sum = 0;
        int count = 0;
        for (IntWritable val : values) {
            sum += val.get();
            count++;
        }
        double avg = sum / count;
        DecimalFormat df = new DecimalFormat("0.00");
        String str = df.format(avg);
        context.write(key, new Text(str));
    }
}
```



### Driver类



```java
import cn.tedu.authinput.AuthInputFormat;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.MultipleInputs;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class ScoreDriver {
    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf);

        job.setJarByClass(ScoreDriver.class);
        job.setReducerClass(ScoreReducer.class);

        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);

        // 多源输入
        MultipleInputs.addInputPath(job, new Path("hdfs://hadoop01:9000/txt/score.txt"),
                TextInputFormat.class, ScoreMapper1.class);
        MultipleInputs.addInputPath(job, new Path("hdfs://hadoop01:9000/txt/score3.txt"),
                AuthInputFormat.class, ScoreMapper2.class);

        FileOutputFormat.setOutputPath(job,
                new Path("hdfs://hadoop01:9000/result/multipleinputs"));
        job.waitForCompletion(true);
    }
}
```





# OutPutFormat - 输出格式

1. OutPutFormat是输出格式的顶级父类，如果需要自定义输出格式，需要继承这个类
2. ==实际开发中，很少自定义输出格式==，而是采用==MapReduce中默认的输出格式==
3. 在MapReduce中，如果没有指定输出格式，那么默认采用的输出格式类为：`TextOutputFormat`



## 多源输出

### Mapper类

```java
public class MoutMapper extends Mapper<LongWritable, Text, Text, Text> {

    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String line = value.toString();
        String[] arr = line.split(" ");
        context.write(new Text(arr[0]), new Text(arr[1]));
    }
}
```



### Reduce类

```java
public class MoutReducer extends Reducer<Text, Text, Text, Text> {

    private MultipleOutputs<Text, Text> mo;

    @Override
    protected void setup(Reducer<Text, Text, Text, Text>.Context context) throws IOException, InterruptedException {
        mo = new MultipleOutputs<>(context);
    }

    public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
        String name = key.toString();
        Text value = values.iterator().next();
        if (name.charAt(0) <= 'I')
            mo.write("a2i", key, value);
        else
            mo.write("j2z", key, value);
    }
}
```



### Driver类

```java
public class MoutDriver {

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "JobName");
        job.setJarByClass(cn.tedu.multiout.MoutDriver.class);
        job.setMapperClass(MoutMapper.class);
        job.setReducerClass(MoutReducer.class);

        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(Text.class);

        FileInputFormat.setInputPaths(job, new Path("hdfs://192.168.32.147:9000/txt/score2.txt"));
        FileOutputFormat.setOutputPath(job, new Path("hdfs://192.168.32.147:9000/result4"));

        MultipleOutputs.addNamedOutput(job, "a2i", TextOutputFormat.class, Text.class, Text.class);
        MultipleOutputs.addNamedOutput(job, "j2z", TextOutputFormat.class, Text.class, Text.class);

        if (!job.waitForCompletion(true))
            return;
    }

}
```

