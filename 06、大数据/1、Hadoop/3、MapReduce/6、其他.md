# 数据倾斜

1. 数据本身具有倾斜的特性。数据本身就是不平均的，数据倾斜不能避免

2. Map端也会产生数据倾斜。倾斜条件：

   - 多源输入
   - 输入的文件不可切分且大小不均等

   Map端的数据倾斜无法避免且无法解决

3. 在实际生产场景中，绝大部分的数据倾斜都是发生在了Reduce端

   > Reduce端产生数据倾斜的本质原因是因为数据本身具有倾斜特性，但是Reduce端产生倾斜的表面原因是因为数据的分类（分区）。
   >
   > 针对Reduce端的数据倾斜，经常采用的方案：==二/两阶段聚合==

## 二/两阶段聚合

> 倾斜度越高，二阶段聚合的效率就越高

1. 先将数据打散，打散之后先分布聚合
2. 按照业务指定分类，对数据进行最后的汇总

![](https://gitee.com/sxhDrk/images/raw/master/imgs/二阶段聚合.png)



# 小文件

1. 小文件的危害

   - 存储：每一个小文件在HDFS上都会产生一条元数据。如果存储大量的小文件，那么就会产生大量的元数据。如果元数据过多，会大量占用NameNode的内存，并且还会导致元数据的查询效率变低
   - 计算：每一个小文件在MapReduce中对应一个切片。如果计算大量的小文件，那么就会产生大量的切片，每一个切片会对应一个MapTask(本质上是一个线程)，大量的切片就会产生大量的线程。如果线程数量过多，这个时候就会导致服务器的效率变低甚至会崩溃

2. 目前为止，市面上针对小文件的常见处理手段：==合并和打包==

3. Hadoop提供了一种原生的打包手段：`Hadoop Archive`，可以将一个或者多个小文件打成一个har包

   > 例如：`hadoop archive -archiveName txt.har -p /txt/`



# 推测执行机制

1. 推测执行机制实际上是Hadoop提供的一种针对慢任务的优化方法：当出现慢任务的时候，Hadoop会将这个慢任务复制一份放到其他节点上，两个节点同时执行相同的任务，谁先执行完，那么结果就作为最后的结果，另一个没有执行完的任务就会被kill掉 
2. 慢任务出现的场景：
   - 任务分配不均匀 
   - 机器性能不均等 
   - 数据倾斜
3. ==实际开发中==，数据倾斜导致的慢任务出现的概率更高，但是此时推测执行机制是无效的，反而还会加剧集群的资源消耗，也因此==一般会关闭推测执行机制==