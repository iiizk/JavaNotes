[TOC]

# 基本结构

1. HDFS中基本架构是由一个NameNode+多个DataNode来组成的
2. 在HDFS中存储数据的时候，会对文件进行切块，切块之后会将不同的数据块（Block）放到不同的节点上
3. 在HDFS中，默认会对每一个Block进行备份，备份称之为副本（replicas）。在HDFS中，连同原来的Block构成3个副本
4. HDFS仿照Linux设计了一套文件存储系统，所以和Linux一样，是以`/`为根路径，每一个文件都存在权限问题



![](https://gitee.com/sxhDrk/images/raw/master/imgs/NameNode收到请求后.png)



# Block

1. 数据块（Block）是HDFS存储数据的基本单位

2. 当在DHFS上存储超大文件时，HDFS会以一个标准将文件切分成几块，分别存储到不同的节点上，切出的数据称为Block

   > 每一个Block的大小默认不超过128MB
   >
   > 假设一个文件是1GB，那么这个文件会被切成8个Block
   >
   > - 这个Block的大小可以通过`dfs.blocksize`属性来设置
   >
   > - 单位是字节。
   >
   > - 配置文件的位置：`/home/ssoftware/hadoop-2.7.1/etc/hadoop/hdfs-site.xml`

3. 如果文件大小不足128MB，那么这个文件是多大，所对应的的Block就是多大。

   > 例如：一个文件是20MB，那么这个文件对应的Block大小就是20MB
   >
   > 如果文件是150MB，那么这个文件对应了2个Block：128MB+22MB

4. 每一个Block分配一个BlockID

**切块的意义**：

- 能够存储超大文件
- 能够快速备份



# NameNode

> NameNode负责管理==DataNode==和记录==元数据==

## 元数据

1. 元数据：描述数据的数据

   - 文件在HDFS的存储位置
   - 上传的用户及用户组
   - 文件的权限
   - 文件的大小
   - Block的大小
   - 文件和BlockID的映射关系
   - 副本数量
   - Block和DataNode的映射

2. NameNode将元数据维系在==内存==和==硬盘==中

   - 维系在内存中的目的是为了查询快
   - 维系在磁盘中的目的是为了崩溃恢复

3. 元数据在磁盘中的存储位置由：`hadoop.tmp.dir`来决定，如果不配置，那么默认放在`/tmp`下

4. 元数据的存储和edits以及fsimage文件相关

   - edits：记录==写操作==的文件
   - fsimage：记录==元数据==的文件，但是这个文件的元数据和内存中的元数据不是同步的。fsimage中的元数据往往是落后于内存中的元数据

5. 当NameNode收到请求之后，NameNode先将这个请求记录到`edits_inprogress`中，记录成功之后修改内存中的元数据，内存中的元数据修改成功之后会给客户端返回一个ACK，表示成功。这个过程不会涉及到fsimage文件的修改

   ![](https://gitee.com/sxhDrk/images/raw/master/imgs/edits的滚动.png)

6. 当NameNode收到读请求后，直接查阅内存中的元数据，此时不涉及edits和fsimage

7. 存储元数据的目录：`dfs/name/current`

## 持久化文件：edits和fsimage

1. 在达到合适条件的时候，触发`edits`文件的滚动和`fsimage`文件的更新：

   - `edits_inprogress`会滚动生成`edits`文件
   - 同时这个过程中更新`fsimage`中的元数据
   - 产生一个新的`edits_inprogress`

   ![](https://gitee.com/sxhDrk/images/raw/master/imgs/HDFS节点状态.png)

2. edits_inprogress文件的滚动条件

   - ==空间==：当`edits_inprogress`文件达到指定大小时，会产生滚动

     > 默认是64MB
     >
     > 这个大小可以通过`fs.checkpoint.size`来调节
     >
     > 单位是字节
     >
     > 这个属性是放在`core-site.xml`中的

   - ==时间==：当距离上一次更新达到指定时间间隔之后，会产生滚动

     > 默认是3600s（1天）
     >
     > 这个大小可以通过`fs.checkpoint.period`来调节
     >
     > 单位是s（秒）
     >
     > 这个属性是放在`core-site.xml`中的

   - 重启：当HDFS/NameNode重启的时候，触发`edits_inprogress`文件的滚动

   - 强制：`Hadoop dfsadmin -rollEdits`

## NameNode

1. NameNode通过心跳机制来管理DataNode

2. DataNode会定时给NameNode发送心跳信息

   > 默认是3s
   >
   > 这个值可以通过`dfs.heartbeat.interval`来修改
   >
   > 这个属性是配置在`hdfs-site.xml`中的

3. 心跳机制通过RPC来实现的

4. 当NameNode超过10min没有收到DataNode的心跳，NameNode就会认为这个DataNode已经lost（丢失），那么NameNode就会将这个DataNode上的数据备份到其他节点上从而保证整个集群中的副本数量

5. 心跳信息：

   - clusterid（集群编号）：

     > 当HDFS搭建好后，对NameNode进行格式化（Hadoop namenode -format）,格式化的时候自动计算产生一个clusterid。
     >
     > 每次格式化都会重新计算这个clusterid。
     >
     > 当HDFS集群启动之后，NameNode将这个clusterid分发给每一个DataNode，并且要求DataNode发送的每一条心跳中都携带这个clusterid
     >
     > NameNode在收到DataNode的信息之后也会先校验这个clusterid是否一致

   - 当前节点状态：预服役、服役、预退役

     ![](https://gitee.com/sxhDrk/images/raw/master/imgs/HDFS基本结构.png)

   - 当前节点存储的Block的BlockID
   
6. 在Hadoop2.0的集群中:

   - 如果存在`SecondaryNameNode`，则更新过程需要`SecondaryNameNode`参与
   - 如果不存在`SecondaryNameNode`，则更新过程发生在`NameNode`上

7. 无论是Hadoop1.0还是2.0，当HDFS启动NameNode会做一次edits和fsimage合并的操作。这样做的目的是确保fsimage里的元数据更新

8. 当HDFS启动的时候，NameNode会将fsimage中的元数据信息加载到内存中，然后等待每个DataNode向NameNode汇报自身的存储的信息，比如存储了哪些文件块，块大小，块id等。NameNode收到这些信息之后，会做汇总和检测，检测数据是否完整，副本数量是否达到要求，如果检测出现问题，HDFS会进入安全模式，在安全模式做数据或副本的复制，直到修复完成后，安全模式自动退出

9. 如果HDFS处于安全模式，只能对外读服务，不能写服务

10. 在Hadoop1.0中，NameNode存在单点故障问题。在Hadoop2.0的伪分布式中，NameNode依然存在单点故障，但是在Hadoop2.0的全分布式中，可以通过舍弃SecondaryNameNode的方式来配置2个NameNode来保证NameNode的高可用





# SecondaryNameNode

1. SecondaryNameNode不是NameNode的备份，仅仅是辅助NameNode来进行edits文件的滚动和fsimage文件的更新的

2. edits_inprogress文件的滚动：

   - 如果存在SecondaryNameNode，那么edits_inprogress文件的滚动过程是发生在SecondaryNameNode中
   - 如果没有SecondaryNameNode，那么edits_inprogress文件的滚动就发生在NameNode中

3. 到目前为止，HDFS的完全分布式只支持：

   - NameNode+SecondaryNameNode+多个DataNode结构
   - 或者双NameNode+多个DataNode结构

   > 因为在HDFS集群中，NameNode是一个核心节点，如果NameNode只有一个，容易出现单点故障，所有NameNode 必须存在一个备份节点（NameNode做到高可用），就考虑使用：双NameNode+多个DataNode



# DataNode

1. DataNode的职责是用于存储Block
2. 存储Block的位置由`hadoop.tmp.dir`属性来决定
3. DataNode会定时向NameNode发送心跳信息
4. DataNode的节点状态
   - 预服役
   - 服役
   - 预退役
   - 退役





# 副本放置策略

1. 第一个副本：
   - 集群内部上传：谁上传，第一个副本就存在谁身上
   - 集群外部上传：NameNode选择相对比较空闲的节点存放数据
2. 第二个副本：
   - 在Hadoop 2.7之前：放在和第一个副本不同机架的节点上
   - 在Hadoop 2.7开始：放在和第一个副本相同机架的节点上
3. 第三个副本：
   - 在Hadoop 2.7之前：放在和第二个副本相同机架的节点上
   - 在Hadoop 2.7开始：放在和第二个副本不同机架的节点上
4. 更多副本：选择相对空闲的节点放入

# 机架感知策略

1. HDFS中所谓的机架指的并不是物理机架，而是逻辑机架，这个逻辑机架本质上就是一个映射
2. 在实际过程中，可以通过Shell/Python脚本来指定机架，实际上就是制定一个Map，在这个Map中
   - 键：节点主机名/ip地址
   - 值：机架编号
3. 习惯上，会将同一个物理机架或者是同一个用户组内的节点配置在同一个逻辑机架上

